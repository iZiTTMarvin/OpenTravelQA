# 旅游景点智能问答系统 - 小组分工说明

## 项目信息

- **项目名称**：旅游景点智能问答系统
- **课程**：自然语言处理
- **提交日期**：2025年11月

---

## 小组成员

| 角色 | 姓名 | 主要职责 |
|------|------|----------|
| 组长 | 王思琪 | 项目统筹、基于规则的问答实现 |
| 组员 | 禹红倩 | 基于文本分类的问答实现 |
| 组员 | 马成龙 | 基于LLM RAG的问答实现 |
| 组员 | 张楠 | 数据收集与预处理 |
| 组员 | 罗应萍 | PPT制作与项目文档撰写 |

---

## 详细任务分配

### 1. 王思琪（组长）- 基于规则的问答 + 项目统筹

**职责范围：**
- 项目整体架构设计
- 团队任务协调与进度管理
- 基于规则的问答系统开发
- Streamlit主界面开发
- 代码审核与整合

**核心代码文件：**
- `code/rule_based_qa.py` - 基于规则的问答实现
- `main.py` - Streamlit主程序

**关键技术点：**

```python
# ============== 意图识别规则 ==============
# 通过关键词映射表定义不同意图的触发词
意图关键词映射表 = {
    "ASK_TICKET": ["门票", "票价", "多少钱", "收费", "免费", "价格"],
    "ASK_OPEN_TIME": ["开放时间", "营业时间", "几点开门", "几点关门"],
    "ASK_INTRO": ["介绍", "简介", "是什么", "什么样", "怎么样"],
    # ... 更多意图
}

def 识别意图(用户问题: str) -> Tuple[str, float]:
    """
    核心意图识别函数
    工作原理：遍历所有意图，统计关键词匹配数量，选择匹配最多的意图
    """
    最高匹配数 = 0
    识别到的意图 = "UNKNOWN"
    
    for 意图, 关键词列表 in 意图关键词映射表.items():
        匹配数 = sum(1 for 关键词 in 关键词列表 if 关键词 in 用户问题)
        if 匹配数 > 最高匹配数:
            最高匹配数 = 匹配数
            识别到的意图 = 意图
    
    return 识别到的意图, 置信度

# ============== 实体识别规则 ==============
def 识别实体(用户问题: str, 实体词典: Dict) -> Dict[str, List[str]]:
    """
    基于词典的实体识别
    从知识库动态构建景点名称、城市名称词典，进行字符串匹配
    """
    识别结果 = {"景点": [], "城市": [], "省份": []}
    
    for 景点名 in 实体词典.get("景点名称", []):
        if 景点名 in 用户问题:
            识别结果["景点"].append(景点名)
    
    return 识别结果

# ============== 槽位填充与回答生成 ==============
回答模板库 = {
    "ASK_TICKET": "【{name}】的门票价格为：{ticket_price}",
    "ASK_OPEN_TIME": "【{name}】的开放时间为：{open_time}",
    # ... 更多模板
}
```

**需要理解的概念：**  直接问ai，可以把你负责的部分的代码发给ai然后问以下的概念
1. 关键词匹配的意图识别
2. 基于词典的实体识别
3. 槽位填充机制
4. 模板化回答生成

---

### 2. 禹红倩 - 基于文本分类的问答

**职责范围：**
- 意图标签体系设计
- 训练数据收集（每类10条以上）
- TF-IDF + LinearSVC 分类器实现
- 模型训练与评估
- 预测接口开发

**核心代码文件：**
- `code/text_classification_qa.py` - 文本分类问答实现

**关键技术点：**

```python
# ============== 意图标签体系 ==============
意图标签列表 = [
    "ASK_TICKET",       # 询问门票价格
    "ASK_OPEN_TIME",    # 询问开放时间
    "ASK_INTRO",        # 询问景点简介
    "ASK_ADDRESS",      # 询问地址位置
    "ASK_PHONE",        # 询问联系电话
    "ASK_WEBSITE",      # 询问官方网站
    "ASK_RATING",       # 询问评分评价
    "ASK_SUGGEST_TIME", # 询问建议游玩时间
    "ASK_TAGS",         # 询问景点标签
    "ASK_TIPS",         # 询问游玩贴士
    "ASK_LOCATION",     # 询问所在位置
    "ASK_RECOMMEND"     # 景点推荐
]

# ============== 训练数据示例 ==============
训练数据集 = {
    "ASK_TICKET": [
        "这个景点门票多少钱",
        "请问门票价格是多少",
        "入场需要花多少钱",
        # ... 至少10条
    ],
    # ... 其他意图
}

# ============== 分类器构建 ==============
class 意图分类器:
    def __init__(self):
        # 创建Pipeline: TF-IDF向量化 + LinearSVC分类
        self.模型管道 = Pipeline([
            ('tfidf', TfidfVectorizer(
                max_features=5000,      # 最大特征数
                ngram_range=(1, 2),     # unigram + bigram
                analyzer='char_wb'      # 字符级别分析
            )),
            ('svc', LinearSVC(
                C=1.0,                  # 正则化参数
                class_weight='balanced' # 平衡类别权重
            ))
        ])
    
    def 训练(self, 问题列表, 标签列表):
        """训练分类模型"""
        self.模型管道.fit(问题列表, 标签列表)
    
    def 预测(self, 问题: str) -> Tuple[str, float]:
        """预测单个问题的意图"""
        分词后问题 = 中文分词(问题)
        预测结果 = self.模型管道.predict([分词后问题])[0]
        return 预测结果, 置信度
```

**需要理解的概念：**   可以直接问ai，可以把你负责的部分的代码发给ai然后问以下的概念
1. TF-IDF（词频-逆文档频率）原理
2. SVM/LinearSVC分类器原理
3. sklearn Pipeline使用
4. 模型训练与评估流程

---

### 3. 马成龙 - 基于LLM RAG的问答

**职责范围：**
- RAG架构设计与实现
- 文档模板设计
- 向量索引构建
- 大模型调用接口开发
- Prompt工程设计

**核心代码文件：**
- `code/llm_rag_qa.py` - LLM RAG问答实现

**关键的技术点：**

```python
# ============== 文档模板 ==============
景点文档模板 = """
【景点名称】{name}
【所在城市】{city}
【所在省份】{province}
【详细地址】{address}
【门票价格】{ticket_price}
【开放时间】{open_time}
【景点简介】{description}
【游玩贴士】{tips}
"""

# ============== 向量检索器 ==============
class 向量检索器:
    def __init__(self):
        # 使用TF-IDF进行简化的向量化
        self.向量化器 = TfidfVectorizer(
            max_features=5000,
            analyzer='char_wb'
        )
    
    def 构建索引(self, 知识库: pd.DataFrame):
        """将所有文档向量化并建立索引"""
        self.文档列表 = 批量构建文档(知识库)
        文档内容列表 = [doc["content"] for doc in self.文档列表]
        self.文档向量 = self.向量化器.fit_transform(文档内容列表)
    
    def 检索(self, 查询文本: str, top_k: int = 3) -> List[Dict]:
        """检索最相关的Top-K文档"""
        查询向量 = self.向量化器.transform([查询文本])
        相似度 = cosine_similarity(查询向量, self.文档向量).flatten()
        top_indices = np.argsort(相似度)[::-1][:top_k]
        return [self.文档列表[i] for i in top_indices]

# ============== Prompt模板 ==============
系统提示词 = """你是一个专业的旅游景点智能问答助手。
重要规则：
1. 只能根据提供的文档内容回答问题
2. 如果文档中没有相关信息，请诚实告知
3. 回答要简洁明了，突出关键信息
"""

用户Prompt模板 = """请根据以下景点信息文档，回答用户的问题。

【参考文档】
{检索文档}

【用户问题】
{用户问题}

请基于以上文档信息回答用户的问题："""

# ============== 大模型调用 ==============
class 大模型客户端:
    def 调用Ollama(self, 系统提示: str, 用户提示: str) -> str:
        """调用本地Ollama模型"""
        请求数据 = {
            "model": "qwen2.5:7b",
            "prompt": f"{系统提示}\n\n{用户提示}",
            "stream": False
        }
        响应 = requests.post("http://localhost:11434/api/generate", json=请求数据)
        return 响应.json().get("response", "")
```

**需要理解的概念：** 直接问ai，可以把你负责的部分的代码发给ai然后问以下的概念
1. RAG（检索增强生成）架构
2. 文档向量化与相似度检索
3. Prompt Engineering（提示词工程）
4. 大模型API调用方式

---

### 4. 张楠 - 数据收集与预处理

**职责范围：**
- 原始数据收集
- 数据清洗与格式化
- 数据质量检查
- 数据字段标准化
- 数据集维护与更新

**核心代码文件：**
- `data_preprocessing.py` - 数据预处理脚本（如需要）
- `data/merged_attractions.csv` - 最终数据集

**关键技术点：**

```python
# ============== 数据加载与检查 ==============
import pandas as pd

def 加载数据(文件路径: str) -> pd.DataFrame:
    """加载CSV数据"""
    return pd.read_csv(文件路径)

def 数据质量检查(df: pd.DataFrame):
    """检查数据质量"""
    print(f"数据总量: {len(df)}")
    print(f"字段列表: {df.columns.tolist()}")
    print(f"缺失值统计:\n{df.isnull().sum()}")
    print(f"重复数据: {df.duplicated().sum()}")

# ============== 数据清洗 ==============
def 清洗数据(df: pd.DataFrame) -> pd.DataFrame:
    """数据清洗"""
    # 去除重复
    df = df.drop_duplicates(subset=['name'])
    # 填充缺失值
    df['phone'] = df['phone'].fillna('暂无')
    df['website'] = df['website'].fillna('暂无')
    # 标准化评分
    df['rating'] = pd.to_numeric(df['rating'], errors='coerce')
    return df

# ============== 数据字段说明 ==============
"""
数据集包含以下字段：
- dataid: 数据唯一标识
- name: 景点名称（必填）
- city: 所在城市（必填）
- province: 所在省份（必填）
- address: 详细地址
- phone: 联系电话
- website: 官方网站
- rating: 用户评分（0-5分）
- ticket_price: 门票价格
- open_time: 开放时间
- suggest_time: 建议游玩时间
- tags: 景点标签（多个标签用|分隔）
- description: 景点描述
- tips: 游玩贴士
"""
```

**需要理解的概念：** 直接问ai，可以把你负责的部分的代码发给ai然后问以下的概念
1. 数据清洗的基本流程
2. Pandas数据处理
3. 数据质量评估方法
4. 数据字段设计原则

---

### 5. 罗应萍 - PPT制作与项目文档

**职责范围：**
- 项目PPT制作
- README文档撰写
- 方法对比分析文档
- 小组分工说明文档
- 项目演示准备

**核心文档文件：**
- `README.md` - 项目说明
- `docs/方法对比分析.md` - 方法对比文档
- `docs/小组分工说明.md` - 本文档
- 项目演示PPT

**文档撰写要点：**

```markdown
# PPT结构建议

1. 封面
   - 项目名称
   - 团队成员
   - 日期

2. 项目背景
   - 问题定义
   - 应用场景
   - 技术挑战

3. 系统架构
   - 整体架构图
   - 数据流程图
   - 模块划分

4. 三种方法详解
   - 基于规则的方法
   - 基于文本分类的方法
   - 基于LLM RAG的方法
   
5. 方法对比
   - 原理对比
   - 优缺点对比
   - 性能对比

6. 系统演示
   - 界面展示
   - 功能演示
   - 效果对比

7. 总结与展望
   - 项目成果
   - 不足与改进
   - 未来工作
```

**需要理解的概念：**
1. 三种方法的基本原理（与组员沟通了解）
2. 系统整体架构
3. 技术选型理由
4. 项目亮点总结

---

## 协作流程

### 1. 项目阶段划分

| 阶段 | 时间 | 主要任务 | 负责人 |
|------|------|----------|--------|
| 第一阶段 | 第1周 | 数据收集与预处理 | 张楠 |
| 第二阶段 | 第2-3周 | 三种方法并行开发 | 王思琪、禹红倩、马成龙 |
| 第三阶段 | 第4周 | 系统整合与测试 | 王思琪 |
| 第四阶段 | 第5周 | 文档撰写与PPT | 罗应萍 |

### 2. 代码协作规范

```
# Git提交规范
feat: 新功能
fix: 修复bug
docs: 文档更新
style: 代码格式调整
refactor: 代码重构
test: 测试相关

# 示例
git commit -m "feat: 完成基于规则的意图识别模块"
```

### 3. 沟通机制

- **日常沟通**：微信群
- **周例会**：每周日晚8点
- **代码共享**：GitHub仓库
- **文档协作**：腾讯文档

---

## 系统运行指南

### 环境配置

```bash
# 1. 安装Python 3.8+

# 2. 安装依赖
pip install -r requirements.txt

# 3. 运行系统
cd wsq
streamlit run main.py

# 4. 访问 http://localhost:8501
```

### 常见问题

**Q: 文本分类模型没有训练？**
A: 首次运行会自动训练并保存模型到 `models/intent_classifier.pkl`

**Q: LLM RAG不工作？**
A: 需要安装Ollama并运行模型，或配置OpenAI API密钥

**Q: 界面样式不正确？**
A: 确保使用最新版本的Streamlit

---

## 考核标准

| 评分项 | 分值 | 评分标准 |
|--------|------|----------|
| 代码实现 | 40% | 功能完整性、代码质量、注释规范 |
| 文档质量 | 20% | 文档完整性、表述清晰度 |
| PPT展示 | 20% | 内容组织、演示效果 |
| 团队协作 | 10% | 分工合理性、协作效率 |
| 创新性 | 10% | 技术创新、功能创新 |

---

*小组分工说明文档 v1.0 | 更新日期: 2025年11月*
